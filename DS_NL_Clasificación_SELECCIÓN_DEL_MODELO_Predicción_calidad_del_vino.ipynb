{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aiadevop/training_model_wine_quality/blob/main/DS_NL_Clasificaci%C3%B3n_SELECCI%C3%93N_DEL_MODELO_Predicci%C3%B3n_calidad_del_vino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "url=\"https://raw.githubusercontent.com/Aiadevop/training_model_wine_quality/refs/heads/main/data/df_cl_final.csv\"\n",
        "df_cl = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "D64RSnhP-vMn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divido los datos para test y entrenamiento.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el DataFrame completo. Test_size 20,80 y random_state es la semilla\n",
        "df_train, df_test = train_test_split(\n",
        "    df_cl, test_size=0.2, random_state=42, stratify=df_cl['quality']\n",
        ")\n",
        "\n",
        "# Luego extraer X e y de cada DataFrame\n",
        "X_train = df_train.drop('quality', axis=1)\n",
        "y_train = df_train['quality']\n",
        "\n",
        "X_test = df_test.drop('quality', axis=1)\n",
        "y_test = df_test['quality']\n",
        "\n",
        "print(f\"Tama√±o df_train: {df_train.shape}\")\n",
        "print(f\"Tama√±o df_test: {df_test.shape}\")\n",
        "print(f\"Distribuci√≥n train: {y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Distribuci√≥n test: {y_test.value_counts(normalize=True)}\")"
      ],
      "metadata": {
        "id": "c_eu80kaFA65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f639e3-2be9-42e7-ca16-ada1a5844545"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tama√±o df_train: (1279, 12)\n",
            "Tama√±o df_test: (320, 12)\n",
            "Distribuci√≥n train: quality\n",
            "1    0.534793\n",
            "0    0.465207\n",
            "Name: proportion, dtype: float64\n",
            "Distribuci√≥n test: quality\n",
            "1    0.534375\n",
            "0    0.465625\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo un modelo base con LogisticRegression ya que es una clasificaci√≥n binaria.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
        "\n",
        "# Crear y entrenar el modelo baseline\n",
        "print(\"üîÑ Entrenando Logistic Regression (baseline)...\")\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "#Hacer predicciones\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "y_pred_proba_lr = lr.predict_proba(X_test)[:, 1]  # Probabilidades para clase 1\n",
        "\n",
        "# Evaluar el modelo\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä RESULTADOS BASELINE - LOGISTIC REGRESSION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_lr)\n",
        "\n",
        "print(f\"üéØ Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
        "print(f\"üìà ROC-AUC: {roc_auc:.3f}\")\n",
        "\n",
        "# Si precision y recall tienen en 0 y 1 un valor similar significa que el modelo no esta sesgado para ninguna clase\n",
        "print(\"\\nüìã Reporte detallado:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"üî¢ Matriz de confusi√≥n:\")\n",
        "cm = confusion_matrix(y_test, y_pred_lr)\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nüìä Interpretaci√≥n de la matriz:\")\n",
        "print(f\"Verdaderos Negativos (TN): {cm[0,0]}\")\n",
        "print(f\"Falsos Positivos (FP): {cm[0,1]}\")\n",
        "print(f\"Falsos Negativos (FN): {cm[1,0]}\")\n",
        "print(f\"Verdaderos Positivos (TP): {cm[1,1]}\")\n",
        "\n",
        "# Variables m√°s importantes (coeficientes)\n",
        "print(\"\\nüîç Top 5 variables m√°s influyentes:\")\n",
        "feature_importance = pd.DataFrame({\n",
        "    'variable': X_train.columns,\n",
        "    'coeficiente': lr.coef_[0],\n",
        "    'importancia_abs': abs(lr.coef_[0])\n",
        "}).sort_values('importancia_abs', ascending=False)\n",
        "\n",
        "print(feature_importance.head())\n",
        "\n",
        "print(f\"\\n‚úÖ BASELINE ESTABLECIDO: {accuracy:.3f} accuracy - Esta es tu m√©trica a superar!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic1uDPddKjEG",
        "outputId": "c3eeb6b2-3d6f-4ded-d18d-7c9d1e2f98c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Entrenando Logistic Regression (baseline)...\n",
            "\n",
            "==================================================\n",
            "üìä RESULTADOS BASELINE - LOGISTIC REGRESSION\n",
            "==================================================\n",
            "üéØ Accuracy: 0.741 (74.1%)\n",
            "üìà ROC-AUC: 0.824\n",
            "\n",
            "üìã Reporte detallado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.74      0.73       149\n",
            "           1       0.77      0.74      0.75       171\n",
            "\n",
            "    accuracy                           0.74       320\n",
            "   macro avg       0.74      0.74      0.74       320\n",
            "weighted avg       0.74      0.74      0.74       320\n",
            "\n",
            "üî¢ Matriz de confusi√≥n:\n",
            "[[111  38]\n",
            " [ 45 126]]\n",
            "\n",
            "üìä Interpretaci√≥n de la matriz:\n",
            "Verdaderos Negativos (TN): 111\n",
            "Falsos Positivos (FP): 38\n",
            "Falsos Negativos (FN): 45\n",
            "Verdaderos Positivos (TP): 126\n",
            "\n",
            "üîç Top 5 variables m√°s influyentes:\n",
            "                variable  coeficiente  importancia_abs\n",
            "10               alcohol     1.251893         1.251893\n",
            "1       volatile_acidity    -0.818797         0.818797\n",
            "6   total_sulfur_dioxide    -0.682987         0.682987\n",
            "9              sulphates     0.538690         0.538690\n",
            "2            citric_acid    -0.452231         0.452231\n",
            "\n",
            "‚úÖ BASELINE ESTABLECIDO: 0.741 accuracy - Esta es tu m√©trica a superar!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Voy a entrenar con distintos modelos a ver cual devuelve mejores m√©tricas.\n",
        "\n",
        "modelos = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    y_proba = modelo.predict_proba(X_test)[:,1]\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    resultados.append({\n",
        "        \"Modelo\": nombre,\n",
        "        \"Accuracy\": acc,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    })\n",
        "\n",
        "# Ordenar resultados por ROC-AUC descendente\n",
        "resultados = sorted(resultados, key=lambda x: x[\"ROC-AUC\"], reverse=True)\n",
        "\n",
        "print(f\"{'Modelo':<20} {'Accuracy':<10} {'ROC-AUC':<10}\")\n",
        "print(\"-\"*45)\n",
        "for r in resultados:\n",
        "    print(f\"{r['Modelo']:<20} {r['Accuracy']:<10.3f} {r['ROC-AUC']:<10.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTd0Tx85GF23",
        "outputId": "63ea5e2f-208f-4c19-d656-dd900b1dcfb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo               Accuracy   ROC-AUC   \n",
            "---------------------------------------------\n",
            "Random Forest        0.806      0.903     \n",
            "SVM                  0.741      0.832     \n",
            "Logistic Regression  0.741      0.824     \n",
            "KNN                  0.731      0.810     \n",
            "Naive Bayes          0.722      0.788     \n",
            "Decision Tree        0.759      0.758     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Crear modelos con configuraci√≥n b√°sica\n",
        "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "lgbm = LGBMClassifier(random_state=42, verbose=-1)\n",
        "\n",
        "# Entrenar y predecir - XGBoost\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "y_proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Entrenar y predecir - LightGBM\n",
        "lgbm.fit(X_train, y_train)\n",
        "y_pred_lgbm = lgbm.predict(X_test)\n",
        "y_proba_lgbm = lgbm.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluar\n",
        "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "roc_xgb = roc_auc_score(y_test, y_proba_xgb)\n",
        "\n",
        "acc_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "roc_lgbm = roc_auc_score(y_test, y_proba_lgbm)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"üìà RESULTADOS BOOSTING üìà\\n\")\n",
        "print(f\"XGBoost      - Accuracy: {acc_xgb:.3f}, ROC-AUC: {roc_xgb:.3f}\")\n",
        "print(f\"LightGBM     - Accuracy: {acc_lgbm:.3f}, ROC-AUC: {roc_lgbm:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcRDVqlbvM0o",
        "outputId": "3eb5e4da-6af7-495e-9488-89bf80a4d14d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà RESULTADOS BOOSTING üìà\n",
            "\n",
            "XGBoost      - Accuracy: 0.825, ROC-AUC: 0.896\n",
            "LightGBM     - Accuracy: 0.816, ROC-AUC: 0.890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Con estos datos se puede observar que el mejor modelo para el entrenamiento es RandomForest y estos dos √∫ltimos, voy a ajustar hiperpar√°metros en los tres modelos para ver con cual obtengo mejor resultado."
      ],
      "metadata": {
        "id": "soSeAAKGv-KX"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}